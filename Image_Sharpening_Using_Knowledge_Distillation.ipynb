{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dedeepyamaddi/intel-unnati/blob/main/Image_Sharpening_Using_Knowledge_Distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPm7iAHYmy8U",
        "outputId": "130bf604-6ee8-458a-9d8c-f39be1683229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=4ab8212ef439f6b13776c988a40248b56833d5b0099669629147d71d7e34be4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ],
      "source": [
        "pip install fpdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XcEVol97Aeh",
        "outputId": "5e2de0d2-082e-48cf-dcde-7d76bc262d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "➡️ Training student model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 5/5 [00:13<00:00,  2.61s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Loss: 0.002520\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 5/5 [00:13<00:00,  2.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Loss: 0.000990\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 5/5 [00:12<00:00,  2.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Loss: 0.000757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 5/5 [00:11<00:00,  2.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 - Loss: 0.000712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 5/5 [00:12<00:00,  2.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 - Loss: 0.000675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 5/5 [00:12<00:00,  2.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 - Loss: 0.000653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 5/5 [00:11<00:00,  2.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 - Loss: 0.000645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 5/5 [00:12<00:00,  2.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 - Loss: 0.000638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 5/5 [00:12<00:00,  2.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 - Loss: 0.000632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 5/5 [00:12<00:00,  2.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 - Loss: 0.000627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20: 100%|██████████| 5/5 [00:11<00:00,  2.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 - Loss: 0.000624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20: 100%|██████████| 5/5 [00:12<00:00,  2.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 - Loss: 0.000621\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20: 100%|██████████| 5/5 [00:12<00:00,  2.43s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 - Loss: 0.000619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/20: 100%|██████████| 5/5 [00:12<00:00,  2.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 - Loss: 0.000618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/20: 100%|██████████| 5/5 [00:12<00:00,  2.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 - Loss: 0.000615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/20: 100%|██████████| 5/5 [00:11<00:00,  2.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 - Loss: 0.000614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/20: 100%|██████████| 5/5 [00:12<00:00,  2.45s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 - Loss: 0.000612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/20: 100%|██████████| 5/5 [00:12<00:00,  2.44s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 - Loss: 0.000612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/20: 100%|██████████| 5/5 [00:12<00:00,  2.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 - Loss: 0.000611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/20: 100%|██████████| 5/5 [00:12<00:00,  2.48s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 - Loss: 0.000611\n",
            "➡️ Evaluating and saving results...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 5/5 [00:03<00:00,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Average SSIM: 94.08%\n",
            "➡️ Generating PDF report...\n",
            "✅ PDF report saved as 'report.pdf'\n",
            "✅ Training log saved as 'training.json'\n",
            "✅ Model saved as 'student_model.pth'\n",
            "\n",
            "--- DONE ---\n",
            "Average SSIM: 94.08%\n",
            "Enhanced images: enhanced_output/\n",
            "Originals: originals/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from fpdf import FPDF\n",
        "import shutil\n",
        "from IPython.display import FileLink, display\n",
        "\n",
        "# -------- Image Preprocessing ----------\n",
        "def down_upscale_image(img_path, scale=0.75, resize_to=256):\n",
        "    try:\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "    except (UnidentifiedImageError, OSError):\n",
        "        raise ValueError(f\"Image '{img_path}' is unreadable or corrupted.\")\n",
        "    img = img.resize((resize_to, resize_to), Image.BICUBIC)\n",
        "    w, h = img.size\n",
        "    img_down = img.resize((int(w * scale), int(h * scale)), Image.BICUBIC)\n",
        "    img_up = img_down.resize((w, h), Image.BICUBIC)\n",
        "    return img, img_up\n",
        "\n",
        "# -------- Dataset ----------\n",
        "class SharpnessDataset(Dataset):\n",
        "    def __init__(self, image_dir, scale=0.75, resize_to=256):\n",
        "        self.image_dir = image_dir\n",
        "        self.scale = scale\n",
        "        self.resize_to = resize_to\n",
        "        self.images = [f for f in os.listdir(image_dir)\n",
        "                       if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        self.transform = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        high_res, degraded = down_upscale_image(img_path, self.scale, self.resize_to)\n",
        "        return self.transform(degraded), self.transform(high_res), self.images[idx]\n",
        "\n",
        "# -------- Model ----------\n",
        "class LightDnCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 3, 3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x - self.layers(x)\n",
        "\n",
        "# -------- Training ----------\n",
        "def train_student(teacher, student, dataloader, device, epochs=10, alpha=0.7):\n",
        "    teacher.eval()\n",
        "    student.train()\n",
        "    optimizer = torch.optim.Adam(student.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    logs = {\"loss_per_epoch\": []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for degraded, high_res, _ in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            degraded, high_res = degraded.to(device), high_res.to(device)\n",
        "            with torch.no_grad():\n",
        "                teacher_output = teacher(degraded)\n",
        "            student_output = student(degraded)\n",
        "            loss_gt = loss_fn(student_output, high_res)\n",
        "            loss_teacher = loss_fn(student_output, teacher_output)\n",
        "            loss = alpha * loss_teacher + (1 - alpha) * loss_gt\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        logs[\"loss_per_epoch\"].append(avg_loss)\n",
        "        print(f\"Epoch {epoch+1} - Loss: {avg_loss:.6f}\")\n",
        "    return logs\n",
        "\n",
        "# -------- Evaluation & Saving ----------\n",
        "def evaluate_and_save(model, dataloader, device, save_folder='enhanced_output', originals_folder='originals', input_folder='images'):\n",
        "    model.eval()\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    os.makedirs(originals_folder, exist_ok=True)\n",
        "    total_ssim = 0.0\n",
        "    count = 0\n",
        "    mos_feedback = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for degraded, high_res, filenames in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            degraded = degraded.to(device)\n",
        "            output = model(degraded).cpu().numpy()\n",
        "            target = high_res.numpy()\n",
        "\n",
        "            for i in range(len(output)):\n",
        "                out_img = np.moveaxis(output[i], 0, -1)\n",
        "                tgt_img = np.moveaxis(target[i], 0, -1)\n",
        "                out_img = np.clip(out_img, 0, 1)\n",
        "                out_uint8 = (out_img * 255).astype(np.uint8)\n",
        "\n",
        "                score = ssim(out_img, tgt_img, channel_axis=-1, data_range=1.0)\n",
        "                total_ssim += score\n",
        "                count += 1\n",
        "                filename = filenames[i]\n",
        "                Image.fromarray(out_uint8).save(os.path.join(save_folder, f'sharp_{filename}'))\n",
        "                shutil.copy2(os.path.join(input_folder, filename), os.path.join(originals_folder, filename))\n",
        "                mos_feedback[filename] = round(float(score * 100), 2)\n",
        "\n",
        "    avg_ssim = total_ssim / count\n",
        "    print(f\"✅ Average SSIM: {avg_ssim * 100:.2f}%\")\n",
        "\n",
        "    with open(\"mos_feedback.json\", \"w\") as f:\n",
        "        json.dump(mos_feedback, f, indent=2)\n",
        "\n",
        "    return avg_ssim\n",
        "\n",
        "# -------- PDF Report ----------\n",
        "def generate_pdf_report(avg_ssim, training_logs, pdf_path=\"report.pdf\"):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=16)\n",
        "    pdf.cell(200, 10, txt=\"Image Sharpness Report\", ln=True, align='C')\n",
        "    pdf.ln(10)\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.cell(200, 10, txt=f\"Average SSIM: {avg_ssim * 100:.2f}%\", ln=True)\n",
        "    pdf.ln(5)\n",
        "    pdf.cell(200, 10, txt=\"Training Loss per Epoch:\", ln=True)\n",
        "    for i, loss in enumerate(training_logs[\"loss_per_epoch\"], 1):\n",
        "        pdf.cell(200, 8, txt=f\"Epoch {i}: {loss:.6f}\", ln=True)\n",
        "    pdf.output(pdf_path)\n",
        "    print(f\"✅ PDF report saved as '{pdf_path}'\")\n",
        "\n",
        "    with open(\"training.json\", \"w\") as f:\n",
        "        json.dump(training_logs, f, indent=2)\n",
        "    print(\"✅ Training log saved as 'training.json'\")\n",
        "\n",
        "# -------- Main Pipeline --------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    input_folder = \"images\"\n",
        "    if not os.path.exists(input_folder) or len(os.listdir(input_folder)) == 0:\n",
        "        raise FileNotFoundError(f\"❌ No images found in '{input_folder}'. Please add your dataset.\")\n",
        "\n",
        "    teacher = LightDnCNN().to(device)\n",
        "    student = LightDnCNN().to(device)\n",
        "\n",
        "    dataset = SharpnessDataset(input_folder, scale=0.75, resize_to=256)\n",
        "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "    print(\"➡️ Training student model...\")\n",
        "    logs = train_student(teacher, student, dataloader, device, epochs=20)\n",
        "\n",
        "    print(\"➡️ Evaluating and saving results...\")\n",
        "    avg_ssim = evaluate_and_save(student, dataloader, device)\n",
        "\n",
        "    print(\"➡️ Generating PDF report...\")\n",
        "    generate_pdf_report(avg_ssim, logs)\n",
        "\n",
        "    torch.save(student.state_dict(), 'student_model.pth')\n",
        "    print(\"✅ Model saved as 'student_model.pth'\")\n",
        "\n",
        "    print(\"\\n--- DONE ---\")\n",
        "    print(f\"Average SSIM: {avg_ssim * 100:.2f}%\")\n",
        "    print(\"Enhanced images: enhanced_output/\")\n",
        "    print(\"Originals: originals/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOJyk_gvd8qa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFDJ/eZdwUQhA2Wfsg6qCC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}